{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f752a183",
   "metadata": {},
   "source": [
    "# Generate a text-based story that takes inspiration from a provided prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e6ee6",
   "metadata": {},
   "source": [
    "### Provide the candidate with a prompt or a few keywords, such as \"a haunted house,\" \"an unexpected visitor,\" or \"a time travel adventure.\" Ask them to use GPT-3 to generate a compelling story that incorporates the prompt or keywords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c58811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f07709",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e4d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "prompt = (\"an unexpected visitor \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4188c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the OpenAI API parameters\n",
    "model_engine = \"davinci\"\n",
    "temperature = 0.7\n",
    "max_tokens = 512\n",
    "stop_sequence = \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a249b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the story\n",
    "response = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    stop=stop_sequence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be790da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the generated story from the response\n",
    "generated_text = response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c17ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrived along with the food. The poor little thing was \t\t\t\t\t\t\t\t\ttrapped in a wire mesh box that had served as a cage for \t\t\t\t\t\t\t\t\tguinea pigs. It was so frightened that it wouldnâ€™t come \t\t\t\t\t\t\t\t\tout. We tried to get it to come out, but it just ran into the \t\t\t\t\t\t\t\t\tback of the cage, so we cut the wire and took it out.\n"
     ]
    }
   ],
   "source": [
    "# Print the generated story\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b8eca86",
   "metadata": {},
   "source": [
    "This code uses OpenAI's GPT-3 API to generate a text-based story based on the prompt \"An unexpected visitor arrived at the door. Describe what happens next.\" You'll need to replace \"YOUR_API_KEY\" with your OpenAI API key.\n",
    "\n",
    "This code sends the prompt to the GPT-3 engine and generates a response. It then prints the generated story to the console. You can adjust the parameters such as the temperature, max_tokens, and frequency_penalty to generate different stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ee5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
